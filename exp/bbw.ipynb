{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/data/projects/punim2016/zexianh/LMSeg\")\n",
    "\n",
    "import pyvista as pv\n",
    "pv.start_xvfb()  \n",
    "\n",
    "w_size = (1000, 1000)\n",
    "zoom = 1.2\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from pathlib import PosixPath\n",
    "from data.dataset import BudjBimWallMeshDataset\n",
    "\n",
    "idx = 140\n",
    "bbw_set = BudjBimWallMeshDataset(root='data/BBW', split='test', test_area='area2')\n",
    "\n",
    "dual = bbw_set[idx]\n",
    "mesh = pv.read(PosixPath(str(bbw_set.data_files[idx]).replace(\"/processed/\", \"/mesh/\")).with_suffix(\".ply\"))\n",
    "\n",
    "face_v = dual.pos.cpu().numpy()\n",
    "\n",
    "face_adj = dual.edge_index.cpu().t().numpy()\n",
    "face_adj = np.hstack((np.full((face_adj.shape[0], 1), 2), face_adj))\n",
    "\n",
    "f_normal = dual.normals.cpu().numpy()\n",
    "f_rgba = dual.face_rgba.cpu().numpy()\n",
    "f_mask = dual.y.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.plot(scalars='RGBA', \n",
    "          rgb=True,\n",
    "          cpos='iso', \n",
    "          window_size=w_size,\n",
    "          zoom=zoom,\n",
    "          show_axes=False,\n",
    "          show_scalar_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.cell_data['Mask'] = f_mask\n",
    "mesh.cell_data.active_scalars_name = 'Mask'\n",
    "mesh.plot(scalars='Mask', \n",
    "          cpos='iso', \n",
    "          window_size=w_size,\n",
    "          zoom=zoom,\n",
    "          show_axes=False,\n",
    "          show_scalar_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_pcd = pv.PolyData(face_v)\n",
    "face_pcd.lines = face_adj\n",
    "face_pcd.point_data['RGBA'] = f_rgba\n",
    "face_pcd.point_data.active_scalars_name = 'RGBA'\n",
    "face_pcd.plot(scalars='RGBA', \n",
    "              rgb=True, \n",
    "              cpos='iso', \n",
    "              window_size=w_size, \n",
    "              zoom=zoom,\n",
    "              render_points_as_spheres=True, \n",
    "              point_size=6, \n",
    "              line_width=1.5,\n",
    "              show_axes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_pcd.point_data['Mask'] = f_mask\n",
    "face_pcd.point_data.active_scalars_name = 'Mask'\n",
    "face_pcd.plot(scalars='Mask', \n",
    "              cpos='iso', \n",
    "              window_size=w_size, \n",
    "              zoom=zoom,\n",
    "              render_points_as_spheres=True, \n",
    "              point_size=6, \n",
    "              line_width=1.5,\n",
    "              show_axes=False,\n",
    "              show_scalar_bar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_pcd.point_data['Normal'] = f_normal[:,-3:]\n",
    "arrows = face_pcd.glyph(orient='Normal', scale=False, factor=1.0, tolerance=0.005)\n",
    "arrows.plot(cpos='iso', \n",
    "            window_size=w_size,\n",
    "            zoom=zoom,\n",
    "            show_axes=False,\n",
    "            show_scalar_bar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "from torchmetrics.classification import BinaryF1Score, BinaryJaccardIndex\n",
    "\n",
    "from train.trainer import Trainer\n",
    "from model.net import LMSegNet\n",
    "from model.PointNet.net import PointNetSeg\n",
    "from model.PointNet2.net import PointNet2\n",
    "from model.RandlaNet.net import RandlaNet\n",
    "from model.DeeperGCN.net import DeeperGCN\n",
    "from model.GraphUNet.net import GraphUNet\n",
    "from model.PointTransformer.net import PointTransformer\n",
    "\n",
    "\n",
    "with open('cfg/bbw/lmseg_feature.yaml', 'r') as f:\n",
    "    cfg = yaml.safe_load(f) \n",
    "    model = LMSegNet(cfg['in_channels'], \n",
    "                     cfg['out_channels'],\n",
    "                     cfg['hid_channels'], \n",
    "                     cfg['num_convs'], \n",
    "                     cfg['pool_factors'], \n",
    "                     cfg['num_nbrs'],\n",
    "                     cfg['num_block'],\n",
    "                     cfg['alpha'], \n",
    "                     cfg['beta'])\n",
    "\n",
    "\n",
    "# with open('cfg/bbw/lmseg_rgb.yaml', 'r') as f:\n",
    "#     cfg = yaml.safe_load(f)    \n",
    "#     model = LMSegNet(cfg['in_channels'], \n",
    "#                      cfg['out_channels'],\n",
    "#                      cfg['hid_channels'], \n",
    "#                      cfg['num_convs'], \n",
    "#                      cfg['pool_factors'], \n",
    "#                      cfg['num_nbrs'],\n",
    "#                      cfg['num_block'],\n",
    "#                      cfg['alpha'], \n",
    "#                      cfg['beta'])\n",
    "\n",
    "\n",
    "# with open('cfg/bbw/lmseg_normals.yaml', 'r') as f:\n",
    "#     cfg = yaml.safe_load(f)    \n",
    "#     model = LMSegNet(cfg['in_channels'], \n",
    "#                      cfg['out_channels'],\n",
    "#                      cfg['hid_channels'], \n",
    "#                      cfg['num_convs'], \n",
    "#                      cfg['pool_factors'], \n",
    "#                      cfg['num_nbrs'],\n",
    "#                      cfg['num_block'],\n",
    "#                      cfg['alpha'], \n",
    "#                      cfg['beta'])\n",
    "\n",
    "\n",
    "# with open('cfg/bbw/randlanet_feature.yaml', 'r') as f:\n",
    "#     cfg = yaml.safe_load(f)    \n",
    "#     model = RandlaNet(cfg['in_channels'], \n",
    "#                       cfg['out_channels'],\n",
    "#                       cfg['decimation'],\n",
    "#                       cfg['num_nbrs'])\n",
    "\n",
    "\n",
    "# with open('cfg/bbw/pointnet_feature.yaml', 'r') as f:    \n",
    "#     cfg = yaml.safe_load(f)    \n",
    "#     import torch_geometric.transforms as T\n",
    "#     bbw_set.transform.transforms.append(T.FixedPoints(cfg['num_points']))\n",
    "#     model = PointNetSeg(cfg['in_channels'], cfg['out_channels'], get_trans_feat=False)   \n",
    "\n",
    "\n",
    "# with open('cfg/bbw/pointnet2_feature.yaml', 'r') as f:\n",
    "#     cfg = yaml.safe_load(f)    \n",
    "#     model = PointNet2(cfg['in_channels'], \n",
    "#                       cfg['out_channels'],\n",
    "#                       cfg['pool_ratio'],\n",
    "#                       cfg['num_nbrs'])\n",
    "\n",
    "\n",
    "# with open('cfg/bbw/ptr_feature.yaml', 'r') as f:\n",
    "#     cfg = yaml.safe_load(f)    \n",
    "#     model = PointTransformer(cfg['in_channels'], \n",
    "#                              cfg['out_channels'], \n",
    "#                              cfg['hid_channels'], \n",
    "#                              cfg['pool_ratio'], \n",
    "#                              cfg['num_nbrs'])\n",
    "    \n",
    "    \n",
    "# with open('cfg/bbw/deepergcn_feature.yaml', 'r') as f:\n",
    "#     cfg = yaml.safe_load(f)    \n",
    "#     model = DeeperGCN(cfg['in_channels'], \n",
    "#                       cfg['out_channels'],\n",
    "#                       cfg['hid_channels'], \n",
    "#                       cfg['num_layers'])\n",
    "\n",
    "\n",
    "# with open('cfg/bbw/gunet_feature.yaml', 'r') as f:\n",
    "#     cfg = yaml.safe_load(f)    \n",
    "#     model = GraphUNet(cfg['in_channels'], \n",
    "#                       cfg['hid_channels'], \n",
    "#                       cfg['out_channels'], \n",
    "#                       cfg['depth'],\n",
    "#                       cfg['pool_ratios'],\n",
    "#                       cfg['sum_res'],\n",
    "#                       cfg['act'])\n",
    "    \n",
    "cfg['path'] = cfg['path'] + '/area2'\n",
    "cfg['device'] = 'cpu'\n",
    "\n",
    "trainer = Trainer(cfg=cfg) \n",
    "model = trainer.load_weights(model, f\"epoch{cfg['epoch']}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(bbw_set, \n",
    "                         batch_size=cfg['batch'], \n",
    "                         shuffle=False, \n",
    "                         num_workers=cfg['workers'])\n",
    "\n",
    "metric_dict = {\n",
    "    'f1': BinaryF1Score(), \n",
    "    'mIoU': BinaryJaccardIndex()\n",
    "    }\n",
    "\n",
    "cm = trainer.eval(model, \n",
    "                  test_loader, \n",
    "                  metric=metric_dict, \n",
    "                  ckpt=f\"epoch{cfg['epoch']}.pth\",\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y = model(Batch.from_data_list([bbw_set[idx]]).to(cfg['device']))['y']\n",
    "    pred = torch.nn.functional.sigmoid(y).detach().cpu().numpy()\n",
    "\n",
    "thred = 0.5\n",
    "pred[pred > thred] = 1\n",
    "pred[pred <= thred] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.cell_data['Pred'] = pred\n",
    "mesh.cell_data.active_scalars_name = 'Pred'\n",
    "mesh.plot(scalars='Pred', \n",
    "          cpos='iso', \n",
    "          window_size=w_size,           \n",
    "          zoom=zoom,\n",
    "          show_axes=False,\n",
    "          show_scalar_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = (pred != f_mask)\n",
    "\n",
    "mesh.cell_data['Error'] = error\n",
    "mesh.cell_data.active_scalars_name = 'Error'\n",
    "mesh.plot(scalars='Error', \n",
    "          cpos='iso', \n",
    "          cmap=['white', 'red'],\n",
    "          window_size=w_size,           \n",
    "          zoom=zoom,\n",
    "          show_axes=False,\n",
    "          show_scalar_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}\n",
    "\n",
    "def hook_encoder(name):\n",
    "    def _hook(mod, inp, out):\n",
    "        pos_down, x_down, batch_down, edge_index_down = out\n",
    "        activations[f'{name}/pos_down']   = [p.detach().cpu().numpy() for p in pos_down]\n",
    "        activations[f'{name}/batch_down'] = [b.detach().cpu().numpy() for b in batch_down]\n",
    "        activations[f'{name}/edge_down']  = [e.detach().cpu().numpy() for e in edge_index_down]\n",
    "    return _hook\n",
    "\n",
    "def hook_tensor(name):\n",
    "    def _hook(mod, inp, out):\n",
    "        activations[name] = out.detach().cpu().numpy()  # [N_pool, d]\n",
    "    return _hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(Batch.from_data_list([bbw_set[idx]]).to(cfg['device']))\n",
    "    Z = out['y'].detach().cpu().squeeze(-1)  # [N]\n",
    "\n",
    "eps = 1e-12\n",
    "P = torch.sigmoid(Z)                      \n",
    "P_np = P.numpy()\n",
    "entropy = -(P_np * np.log(P_np + eps) + (1.0 - P_np) * np.log(1.0 - P_np + eps)) \n",
    "# Normalize for display\n",
    "emin, emax = entropy.min(), entropy.max()\n",
    "entropy_norm = (entropy - emin) / (emax - emin + 1e-12)\n",
    "\n",
    "mesh.cell_data['Entropy'] = entropy_norm\n",
    "mesh.cell_data.active_scalars_name = 'Entropy'\n",
    "\n",
    "mesh.plot(\n",
    "    scalars='Entropy',\n",
    "    cpos='iso',\n",
    "    window_size=(1000, 1050),\n",
    "    zoom=1.2,\n",
    "    cmap='viridis',            # perceptual; high=uncertain\n",
    "    show_axes=False,\n",
    "    show_scalar_bar=True,\n",
    "    scalar_bar_args={\n",
    "        \"title\": \"Uncertainty (Entropy)\",\n",
    "        \"position_x\": 0.2,     # horizontal placement (0 = left, 1 = right)\n",
    "        \"position_y\": 0.0,     # lower values push the bar down\n",
    "        \"title_font_size\": 20,\n",
    "        \"label_font_size\": 16,\n",
    "        \"italic\": False,\n",
    "        \"bold\": True           # honored on some backends; harmless otherwise\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "def pca_whiten(X, n_components=32, seed=0):\n",
    "    \"\"\"PCA -> whiten -> float32 features\"\"\"\n",
    "    pca = PCA(n_components=n_components, whiten=True, random_state=seed)\n",
    "    return pca.fit_transform(np.asarray(X, dtype=np.float32))\n",
    "\n",
    "def l2_normalize(X, eps=1e-12):\n",
    "    n = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    return X / (n + eps)\n",
    "\n",
    "def idw_upsample(src_pos, src_feat, dst_pos, k=1, eps=1e-12, power=2.0):\n",
    "    \"\"\"Inverse distance weighted upsampling.\"\"\"\n",
    "    nbrs = NearestNeighbors(n_neighbors=k).fit(src_pos)\n",
    "    idx = nbrs.kneighbors(dst_pos, return_distance=False)\n",
    "    d2  = np.sum((dst_pos[:, None, :] - src_pos[idx])**2, axis=-1) + eps\n",
    "    w   = 1.0 / (d2 ** (power/2.0))\n",
    "    w   = w / (w.sum(axis=1, keepdims=True) + eps)\n",
    "    feat_k = src_feat[idx]       # (Nd, k, d)\n",
    "    return np.einsum('nk,nkd->nd', w, feat_k)\n",
    "\n",
    "def kmeans_labels(X, n_clusters=8, seed=0):\n",
    "    km = KMeans(n_clusters=n_clusters, n_init=10, random_state=seed)\n",
    "    return km.fit_predict(X).astype(np.int32)\n",
    "\n",
    "h_enc = model.Enc.register_forward_hook(hook_encoder('Enc'))\n",
    "h_hga = model.Enc.down_convs_hier[-1].register_forward_hook(hook_tensor('HGA_deep'))\n",
    "h_lga = model.Enc.down_convs_local[-1].register_forward_hook(hook_tensor('LGA_last'))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    _ = model(Batch.from_data_list([bbw_set[idx]]).to(cfg['device']))\n",
    "\n",
    "pos_list   = activations['Enc/pos_down']\n",
    "pos_orig   = pos_list[0]                   # (N0, 3)\n",
    "pos_deep   = pos_list[-1]                  # (Nd, 3)\n",
    "H_hga_pool = activations['HGA_deep']       # (Nd, d_h)\n",
    "H_lga_pool = activations['LGA_last']       # (Nd, d_l)\n",
    "\n",
    "# PCA-whiten\n",
    "Z_hga = pca_whiten(H_hga_pool, n_components=32, seed=0)\n",
    "Z_lga = pca_whiten(H_lga_pool, n_components=32, seed=0)\n",
    "\n",
    "# L2 normalization\n",
    "Z_hga = l2_normalize(Z_hga)\n",
    "Z_lga = l2_normalize(Z_lga)\n",
    "\n",
    "# K-means clustering\n",
    "n_clusters = 8\n",
    "labels_hga_pool = kmeans_labels(Z_hga, n_clusters=n_clusters, seed=0)\n",
    "labels_lga_pool = kmeans_labels(Z_lga, n_clusters=n_clusters, seed=0)\n",
    "\n",
    "# 4) Upsample back to original resolution\n",
    "labels_hga_full = idw_upsample(pos_deep, labels_hga_pool[:, None], pos_orig, k=1).ravel().astype(np.int32)\n",
    "labels_lga_full = idw_upsample(pos_deep, labels_lga_pool[:, None], pos_orig, k=1).ravel().astype(np.int32)\n",
    "\n",
    "mesh.cell_data['HGA_clusters'] = labels_hga_full\n",
    "mesh.cell_data['LGA_clusters'] = labels_lga_full\n",
    "\n",
    "annotations_hga = {int(i): f\"HGA-{i}\" for i in range(n_clusters)}\n",
    "annotations_lga = {int(i): f\"LGA-{i}\" for i in range(n_clusters)}\n",
    "\n",
    "# plot\n",
    "mesh.cell_data.active_scalars_name = 'HGA_clusters'\n",
    "mesh.plot(\n",
    "    scalars='HGA_clusters',\n",
    "    cpos='iso',\n",
    "    window_size=(800, 800),\n",
    "    zoom=1.1,\n",
    "    cmap='Set3',\n",
    "    categories=True,\n",
    "    annotations=annotations_hga,\n",
    "    show_axes=False,\n",
    "    show_scalar_bar=True,\n",
    "    scalar_bar_args={\"title\": \"\", \"position_x\": 0.2, \"position_y\": 0.0,\n",
    "                     \"title_font_size\": 20, \"label_font_size\": 16, \"italic\": False, \"bold\": True}\n",
    ")\n",
    "\n",
    "mesh.cell_data.active_scalars_name = 'LGA_clusters'\n",
    "mesh.plot(\n",
    "    scalars='LGA_clusters',\n",
    "    cpos='iso',\n",
    "    window_size=(800, 800),\n",
    "    zoom=1.1,\n",
    "    cmap='Set3',\n",
    "    categories=True,\n",
    "    annotations=annotations_lga,\n",
    "    show_axes=False,\n",
    "    show_scalar_bar=True,\n",
    "    scalar_bar_args={\"title\": \"\", \"position_x\": 0.2, \"position_y\": 0.0,\n",
    "                     \"title_font_size\": 20, \"label_font_size\": 16, \"italic\": False, \"bold\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gen Aggr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\", \n",
    "              palette=\"pastel\")\n",
    "sns.set_theme(rc={\"figure.dpi\": 250, \n",
    "                  'savefig.dpi': 250,\n",
    "                  \"axes.spines.right\": False, \n",
    "                  \"axes.spines.top\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_all(arrs):\n",
    "    return [np.asarray(a).reshape(-1) for a in arrs if a is not None]\n",
    "\n",
    "def stack_long(module_name, mode, arrays):\n",
    "    rows = []\n",
    "    for li, a in enumerate(arrays, 1):\n",
    "        if a is None: \n",
    "            continue\n",
    "        flat = np.asarray(a).reshape(-1)\n",
    "        rows += [{\"Module\": module_name, \"Mode\": mode, \"Layer\": li, \"t\": v} for v in flat]\n",
    "    return rows\n",
    "\n",
    "def plot_compact_split_violin(HGA_t_avg, LGA_t_avg, HGA_t_max, LGA_t_max):\n",
    "    df = pd.DataFrame(\n",
    "        stack_long(\"HGA+\", \"t=0.0\", flatten_all(HGA_t_avg)) +\n",
    "        stack_long(\"LGA+\", \"t=0.0\", flatten_all(LGA_t_avg)) +\n",
    "        stack_long(\"HGA+\", \"t=1.0\", flatten_all(HGA_t_max)) +\n",
    "        stack_long(\"LGA+\", \"t=1.0\", flatten_all(LGA_t_max))\n",
    "    )\n",
    "\n",
    "    layers = sorted(df[\"Layer\"].unique())\n",
    "    x_order = []\n",
    "    for l in layers:\n",
    "        x_order += [f\"L{l}\\n(t=0.0)\", f\"L{l}\\n(t=1.0)\"]\n",
    "    df[\"LayerMode\"] = df.apply(lambda r: f\"L{r['Layer']}\\n({r['Mode']})\", axis=1)\n",
    "    df[\"LayerMode\"] = pd.Categorical(df[\"LayerMode\"], categories=x_order, ordered=True)\n",
    "\n",
    "    sns.set_context(\"paper\") \n",
    "    plt.figure(figsize=(9, 4))\n",
    "\n",
    "    ax = sns.violinplot(\n",
    "        data=df, x=\"LayerMode\", y=\"t\",\n",
    "        hue=\"Module\", split=True, inner=\"quartile\", cut=0, linewidth=0.8\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"\", fontsize=10, weight=\"bold\")\n",
    "    ax.set_ylabel(\"t\", fontsize=10, weight=\"bold\")\n",
    "    ax.set_title(\"Learnable t by layer & module â€” HGA+ vs. LGA+\", fontsize=11, weight=\"bold\")\n",
    "\n",
    "    # --- add vertical dotted lines between L1, L2, L3 groups ---\n",
    "    num_per_layer = 2  # each layer has 2 entries (t=0.0, t=1.0)\n",
    "    for i in range(1, len(layers)):  # after L1, after L2\n",
    "        ax.axvline(i * num_per_layer - 0.5, color=\"gray\", linestyle=\"--\", linewidth=0.8)\n",
    "\n",
    "    # legend styling\n",
    "    leg = ax.legend(title=\"Module\", fontsize=9, title_fontsize=9, frameon=False, loc=\"upper left\")\n",
    "    for t in leg.texts: \n",
    "        t.set_fontsize(9)\n",
    "\n",
    "    plt.tight_layout(pad=0.4)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "HGA_t_avg = []\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "  if name in ['Enc.down_convs_hier.0.gen_aggr_avg.t',\n",
    "              'Enc.down_convs_hier.1.gen_aggr_avg.t',\n",
    "              'Enc.down_convs_hier.2.gen_aggr_avg.t']:\n",
    "    HGA_t_avg.append(param.detach().cpu().numpy())\n",
    "\n",
    "LGA_t_avg = []\n",
    "for name, param in model.named_parameters():\n",
    "  if name in ['Enc.down_convs_local.0.gen_aggr_avg.t',\n",
    "              'Enc.down_convs_local.1.gen_aggr_avg.t',\n",
    "              'Enc.down_convs_local.2.gen_aggr_avg.t']:\n",
    "    LGA_t_avg.append(param.detach().cpu().numpy())\n",
    "\n",
    "HGA_t_max = []\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "  if name in ['Enc.down_convs_hier.0.gen_aggr_max.t',\n",
    "              'Enc.down_convs_hier.1.gen_aggr_max.t',\n",
    "              'Enc.down_convs_hier.2.gen_aggr_max.t']:\n",
    "    HGA_t_max.append(param.detach().cpu().numpy())\n",
    "\n",
    "LGA_t_max = []\n",
    "for name, param in model.named_parameters():\n",
    "  if name in ['Enc.down_convs_local.0.gen_aggr_max.t',\n",
    "              'Enc.down_convs_local.1.gen_aggr_max.t',\n",
    "              'Enc.down_convs_local.2.gen_aggr_max.t']:\n",
    "    LGA_t_max.append(param.detach().cpu().numpy())\n",
    "    \n",
    "    \n",
    "plot_compact_split_violin(HGA_t_avg, LGA_t_avg, HGA_t_max, LGA_t_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh \n",
    "import torch\n",
    "\n",
    "test_mask = [] \n",
    "face_areas = []\n",
    "\n",
    "for idx, f in enumerate(bbw_set.mesh_list):\n",
    "    plydata = trimesh.load(f, force=\"mesh\")\n",
    "    \n",
    "    face_areas.append(torch.from_numpy(np.asarray(plydata.area_faces)))\n",
    "    test_mask.append(bbw_set[idx].y.cpu().view(-1).long())\n",
    "    \n",
    "test_mask = torch.hstack(test_mask)\n",
    "face_areas = torch.hstack(face_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import aggr \n",
    "\n",
    "sum_aggr = aggr.SumAggregation()\n",
    "area_per_mask = sum_aggr(face_areas.view(-1, 1), test_mask)\n",
    "\n",
    "area_per_mask / area_per_mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPS Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model.pool import RandomPooling, FPSPooling, EdgeRandomPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pool = 4\n",
    "fps = FPSPooling()\n",
    "\n",
    "p = bbw_set[idx].pos\n",
    "y = bbw_set[idx].y\n",
    "edge_index = bbw_set[idx].edge_index\n",
    "\n",
    "batch = torch.zeros(p.shape[0], dtype=torch.long)\n",
    "ptr = torch.Tensor([0, p.shape[0]]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import radius_graph, knn_graph\n",
    "\n",
    "p_down = [p]\n",
    "y_down = [y]\n",
    "edge_down = [edge_index]\n",
    "\n",
    "for i in range(0, num_pool):    \n",
    "    edge_index_pool, node_index, ptr_pool = fps(p, \n",
    "                                                edge_index, \n",
    "                                                3,\n",
    "                                                ptr)\n",
    "    p_pool = p[node_index]\n",
    "    y_pool = y[node_index]\n",
    "    \n",
    "    p = p_pool\n",
    "    y = y_pool\n",
    "    edge_index = radius_graph(x=p[:,0:2], r= 0.05 * (i + 1), loop=False, max_num_neighbors=3, flow = 'target_to_source')\n",
    "    ptr = ptr_pool\n",
    "    \n",
    "    p_down.append(p)\n",
    "    y_down.append(y)\n",
    "    edge_down.append(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_idx = 3\n",
    "\n",
    "p_pool = p_down[pool_idx].cpu().numpy()\n",
    "y_pool = y_down[pool_idx].cpu().numpy()\n",
    "\n",
    "edge_pool = edge_down[pool_idx].cpu().t().numpy()\n",
    "edge_pool = np.hstack((np.full((edge_pool.shape[0], 1), 2), edge_pool), dtype=edge_pool.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_pcd = pv.PolyData(p_pool)\n",
    "\n",
    "# face_pcd.lines = edge_pool\n",
    "face_pcd.point_data['mask'] = y_pool\n",
    "face_pcd.point_data.active_scalars_name = 'mask'\n",
    "face_pcd.plot(scalars='mask', cmap='viridis', cpos='iso', window_size=w_size, render_points_as_spheres=True, point_size=6, line_width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Decimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pool = 4\n",
    "decimate = RandomPooling()\n",
    "\n",
    "p = bbw_set[idx].pos\n",
    "y = bbw_set[idx].y\n",
    "edge_index = bbw_set[idx].edge_index\n",
    "\n",
    "batch = torch.zeros(p.shape[0], dtype=torch.long)\n",
    "ptr = torch.Tensor([0, p.shape[0]]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import radius_graph, knn_graph\n",
    "from torch_geometric.utils import coalesce, to_undirected\n",
    "\n",
    "p_down = [p]\n",
    "y_down = [y]\n",
    "edge_down = [edge_index]\n",
    "\n",
    "for i in range(0, num_pool):    \n",
    "    edge_index_pool, node_index, ptr_pool = decimate(p[:,0:2], \n",
    "                                                     edge_index, \n",
    "                                                     3,\n",
    "                                                     ptr)\n",
    "    p_pool = p[node_index]\n",
    "    y_pool = y[node_index]\n",
    "    \n",
    "    p = p_pool\n",
    "    y = y_pool\n",
    "    new_edge_index = radius_graph(x=p[:,0:2], \n",
    "                                  r= 0.05 * (i + 1), \n",
    "                                  loop=False, max_num_neighbors=3, \n",
    "                                  flow = 'target_to_source')\n",
    "    edge_index = to_undirected(coalesce(torch.cat([new_edge_index, \n",
    "                                                   edge_index_pool], dim=-1)))\n",
    "    ptr = ptr_pool\n",
    "    \n",
    "    p_down.append(p)\n",
    "    y_down.append(y)\n",
    "    edge_down.append(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_idx = 3\n",
    "\n",
    "p_pool = p_down[pool_idx].cpu().numpy()\n",
    "y_pool = y_down[pool_idx].cpu().numpy()\n",
    "\n",
    "edge_pool = edge_down[pool_idx].cpu().t().numpy()\n",
    "edge_pool = np.hstack((np.full((edge_pool.shape[0], 1), 2), edge_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_pcd = pv.PolyData(p_pool)\n",
    "\n",
    "# face_pcd.lines = edge_pool\n",
    "face_pcd.point_data['mask'] = y_pool\n",
    "face_pcd.point_data.active_scalars_name = 'mask'\n",
    "face_pcd.plot(scalars='mask', cmap='viridis', cpos='iso', window_size=w_size, render_points_as_spheres=True, point_size=6, line_width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Decimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pool = 4\n",
    "edge_decimate = EdgeRandomPooling()\n",
    "\n",
    "p = bbw_set[idx].pos\n",
    "y = bbw_set[idx].y\n",
    "edge_index = bbw_set[idx].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_down = [p]\n",
    "y_down = [y]\n",
    "edge_down = [edge_index]\n",
    "dropout_rate = [0.8, 0.75, 0.75, 0.5]\n",
    "\n",
    "for i in range(0, num_pool):\n",
    "    edge_index_pool, node_index = edge_decimate(p, edge_index)\n",
    "    edge_decimate.dropout_rate = dropout_rate[i]\n",
    "    \n",
    "    p_pool = p[node_index]\n",
    "    y_pool = y[node_index]\n",
    "    \n",
    "    p = p_pool\n",
    "    y = y_pool\n",
    "    edge_index = edge_index_pool\n",
    "    \n",
    "    p_down.append(p)\n",
    "    y_down.append(y)\n",
    "    edge_down.append(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_idx = 2\n",
    "\n",
    "p_pool = p_down[pool_idx].cpu().numpy()\n",
    "y_pool = y_down[pool_idx].cpu().numpy()\n",
    "\n",
    "edge_pool = edge_down[pool_idx].cpu().t().numpy()\n",
    "edge_pool = np.hstack((np.full((edge_pool.shape[0], 1), 2), edge_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_pcd = pv.PolyData(p_pool)\n",
    "\n",
    "face_pcd.lines = edge_pool\n",
    "face_pcd.point_data['mask'] = y_pool\n",
    "face_pcd.point_data.active_scalars_name = 'mask'\n",
    "face_pcd.plot(scalars='mask', cmap='viridis', cpos='iso', window_size=w_size, render_points_as_spheres=True, point_size=6, line_width=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
